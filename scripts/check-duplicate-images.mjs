import { config } from 'dotenv';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';
import pg from 'pg';

const { Client } = pg;

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

config({ path: join(__dirname, '..', '.env.local') });

async function main() {
  const client = new Client({ connectionString: process.env.POSTGRES_URL });
  await client.connect();

  console.log('ğŸ” ì´ë¯¸ì§€ ì¤‘ë³µ ë¶„ì„\n');

  // ê°€ì¥ ë§ì´ ì¤‘ë³µëœ ì´ë¯¸ì§€ URL
  const duplicates = await client.query(`
    SELECT image_url, COUNT(*) as count
    FROM product_images
    GROUP BY image_url
    HAVING COUNT(*) > 20
    ORDER BY count DESC
    LIMIT 30
  `);

  console.log('ğŸ“Š ì¤‘ë³µì´ ì‹¬í•œ ì´ë¯¸ì§€ (20íšŒ ì´ìƒ):');
  console.log('='.repeat(90));
  duplicates.rows.forEach((row, idx) => {
    const url = row.image_url.substring(0, 70);
    console.log(`${(idx+1).toString().padStart(2)}. [${String(row.count).padStart(4)}íšŒ] ${url}`);
  });

  // ì „ì²´ í†µê³„
  const stats = await client.query(`
    SELECT
      COUNT(DISTINCT image_url) as unique_images,
      COUNT(*) as total_images,
      (COUNT(*) - COUNT(DISTINCT image_url)) as duplicate_count
    FROM product_images
  `);

  const dupePercent = ((stats.rows[0].duplicate_count / stats.rows[0].total_images) * 100).toFixed(1);

  console.log('\nğŸ“ˆ ì „ì²´ ì´ë¯¸ì§€ í†µê³„:');
  console.log(`   ì´ ì´ë¯¸ì§€ ë ˆì½”ë“œ:  ${stats.rows[0].total_images}ê°œ`);
  console.log(`   ê³ ìœ í•œ URL:        ${stats.rows[0].unique_images}ê°œ`);
  console.log(`   ì¤‘ë³µëœ ë ˆì½”ë“œ:     ${stats.rows[0].duplicate_count}ê°œ (${dupePercent}%)`);

  await client.end();
  process.exit(0);
}

main().catch(error => {
  console.error('âŒ ì˜¤ë¥˜:', error);
  process.exit(1);
});
